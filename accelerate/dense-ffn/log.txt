Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 64
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 3002.91ms
iter 1: time 3840.47ms
iter 2: time 3839.86ms
iter 3: time 3841.64ms
iter 4: time 3839.12ms
iter 5: time 3839.25ms
iter 6: time 3839.05ms
iter 7: time 3860.62ms
iter 8: time 3869.72ms
iter 9: time 3868.84ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 1614.64ms
iter 1: time 1922.12ms
iter 2: time 1925.05ms
iter 3: time 1924.97ms
iter 4: time 1926.35ms
iter 5: time 1927.02ms
iter 6: time 1927.46ms
iter 7: time 1927.28ms
iter 8: time 1928.90ms
iter 9: time 1928.95ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 989.29ms
iter 1: time 985.23ms
iter 2: time 987.53ms
iter 3: time 987.32ms
iter 4: time 987.35ms
iter 5: time 987.46ms
iter 6: time 987.26ms
iter 7: time 987.88ms
iter 8: time 987.40ms
iter 9: time 987.69ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 624.20ms
iter 1: time 504.11ms
iter 2: time 509.65ms
iter 3: time 506.45ms
iter 4: time 509.13ms
iter 5: time 506.53ms
iter 6: time 509.29ms
iter 7: time 506.48ms
iter 8: time 510.03ms
iter 9: time 506.17ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 482.14ms
iter 1: time 280.21ms
iter 2: time 276.19ms
iter 3: time 277.73ms
iter 4: time 279.97ms
iter 5: time 279.67ms
iter 6: time 277.99ms
iter 7: time 277.88ms
iter 8: time 278.95ms
iter 9: time 279.42ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 64
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 4221.29ms
iter 1: time 6735.51ms
iter 2: time 6757.29ms
iter 3: time 6766.47ms
iter 4: time 6772.58ms
iter 5: time 6776.47ms
iter 6: time 6780.85ms
iter 7: time 6781.44ms
iter 8: time 6785.69ms
iter 9: time 6787.27ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 2266.09ms
iter 1: time 3375.88ms
iter 2: time 3380.31ms
iter 3: time 3381.62ms
iter 4: time 3381.47ms
iter 5: time 3382.30ms
iter 6: time 3382.84ms
iter 7: time 3383.32ms
iter 8: time 3384.51ms
iter 9: time 3385.37ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 1319.75ms
iter 1: time 1643.01ms
iter 2: time 1643.45ms
iter 3: time 1644.68ms
iter 4: time 1644.62ms
iter 5: time 1645.83ms
iter 6: time 1645.64ms
iter 7: time 1645.59ms
iter 8: time 1645.76ms
iter 9: time 1646.44ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 784.87ms
iter 1: time 842.05ms
iter 2: time 844.76ms
iter 3: time 847.83ms
iter 4: time 847.99ms
iter 5: time 847.90ms
iter 6: time 847.98ms
iter 7: time 848.40ms
iter 8: time 847.83ms
iter 9: time 848.10ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 541.55ms
iter 1: time 460.91ms
iter 2: time 445.50ms
iter 3: time 450.10ms
iter 4: time 447.14ms
iter 5: time 448.57ms
iter 6: time 450.39ms
iter 7: time 448.24ms
iter 8: time 450.65ms
iter 9: time 450.06ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 64
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 10367.62ms
iter 1: time 25000.59ms
iter 2: time 25087.16ms
iter 3: time 25223.36ms
iter 4: time 25237.55ms
iter 5: time 25246.86ms
iter 6: time 25246.86ms
iter 7: time 25254.20ms
iter 8: time 25247.02ms
iter 9: time 25246.50ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 6726.58ms
iter 1: time 12514.40ms
iter 2: time 12536.74ms
iter 3: time 12545.13ms
iter 4: time 12603.48ms
iter 5: time 12617.98ms
iter 6: time 12622.47ms
iter 7: time 12626.17ms
iter 8: time 12628.33ms
iter 9: time 12628.64ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 3234.56ms
iter 1: time 6106.68ms
iter 2: time 6107.56ms
iter 3: time 6116.06ms
iter 4: time 6119.54ms
iter 5: time 6121.07ms
iter 6: time 6122.94ms
iter 7: time 6142.33ms
iter 8: time 6147.28ms
iter 9: time 6146.84ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 1797.63ms
iter 1: time 3106.68ms
iter 2: time 3105.53ms
iter 3: time 3107.20ms
iter 4: time 3108.13ms
iter 5: time 3107.43ms
iter 6: time 3107.88ms
iter 7: time 3107.61ms
iter 8: time 3110.41ms
iter 9: time 3110.52ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 1000.73ms
iter 1: time 1602.10ms
iter 2: time 1603.98ms
iter 3: time 1603.84ms
iter 4: time 1603.79ms
iter 5: time 1605.05ms
iter 6: time 1605.38ms
iter 7: time 1605.77ms
iter 8: time 1606.02ms
iter 9: time 1605.93ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 64
Overriding: n_head = 64
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 17010.55ms
iter 1: time 38294.64ms
iter 2: time 38411.34ms
iter 3: time 38421.02ms
iter 4: time 38398.08ms
iter 5: time 38471.48ms
iter 6: time 38489.07ms
iter 7: time 38585.86ms
iter 8: time 38587.72ms
iter 9: time 38609.10ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 32
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 7406.86ms
iter 1: time 19107.26ms
iter 2: time 19137.34ms
iter 3: time 19152.95ms
iter 4: time 19222.01ms
iter 5: time 19248.68ms
iter 6: time 19251.69ms
iter 7: time 19253.36ms
iter 8: time 19258.83ms
iter 9: time 19255.24ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 32
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 3835.66ms
iter 1: time 9417.51ms
iter 2: time 9439.22ms
iter 3: time 9445.99ms
iter 4: time 9447.02ms
iter 5: time 9450.60ms
iter 6: time 9455.00ms
iter 7: time 9452.62ms
iter 8: time 9456.77ms
iter 9: time 9457.68ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 32
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 2099.54ms
iter 1: time 4770.08ms
iter 2: time 4781.46ms
iter 3: time 4782.79ms
iter 4: time 4786.99ms
iter 5: time 4788.60ms
iter 6: time 4790.41ms
iter 7: time 4795.06ms
iter 8: time 4794.93ms
iter 9: time 4799.13ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 32
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 1226.99ms
iter 1: time 2447.69ms
iter 2: time 2451.55ms
iter 3: time 2459.50ms
iter 4: time 2459.87ms
iter 5: time 2462.80ms
iter 6: time 2463.58ms
iter 7: time 2463.98ms
iter 8: time 2464.83ms
iter 9: time 2466.12ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 32
Overriding: n_embd = 4096
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 407.38M
iter 0: time 15628.97ms
iter 1: time 46639.03ms
iter 2: time 46907.99ms
iter 3: time 46933.67ms
iter 4: time 46942.16ms
iter 5: time 46951.52ms
iter 6: time 46961.66ms
iter 7: time 46950.82ms
iter 8: time 46952.70ms
iter 9: time 46926.82ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 32
Overriding: n_embd = 4096
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 407.38M
iter 0: time 7069.63ms
iter 1: time 22997.43ms
iter 2: time 23096.90ms
iter 3: time 23111.11ms
iter 4: time 23176.54ms
iter 5: time 23245.40ms
iter 6: time 23244.43ms
iter 7: time 23242.90ms
iter 8: time 23246.13ms
iter 9: time 23245.09ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 32
Overriding: n_embd = 4096
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 407.38M
iter 0: time 3764.66ms
iter 1: time 11624.99ms
iter 2: time 11705.58ms
iter 3: time 11719.43ms
iter 4: time 11732.18ms
iter 5: time 11731.02ms
iter 6: time 11730.33ms
iter 7: time 11734.75ms
iter 8: time 11738.51ms
iter 9: time 11738.89ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 32
Overriding: n_embd = 4096
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 407.38M
iter 0: time 2263.37ms
iter 1: time 5996.69ms
iter 2: time 6016.13ms
iter 3: time 6030.27ms
iter 4: time 6040.90ms
iter 5: time 6046.95ms
iter 6: time 6051.10ms
iter 7: time 6052.67ms
iter 8: time 6054.23ms
iter 9: time 6057.28ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 40
Overriding: n_embd = 5120
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 572.14M
iter 0: time 27304.87ms
iter 1: time 72362.71ms
iter 2: time 72615.22ms
iter 3: time 72665.35ms
iter 4: time 72683.45ms
iter 5: time 72703.04ms
iter 6: time 72680.06ms
iter 7: time 72697.53ms
iter 8: time 72710.00ms
iter 9: time 72689.62ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 40
Overriding: n_embd = 5120
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 572.14M
iter 0: time 10222.21ms
iter 1: time 36070.45ms
iter 2: time 36327.04ms
iter 3: time 36411.16ms
iter 4: time 36421.12ms
iter 5: time 36419.77ms
iter 6: time 36418.53ms
iter 7: time 36423.61ms
iter 8: time 36415.22ms
iter 9: time 36418.47ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 40
Overriding: n_embd = 5120
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 572.14M
iter 0: time 5310.76ms
iter 1: time 18252.40ms
iter 2: time 18389.58ms
iter 3: time 18417.43ms
iter 4: time 18425.86ms
iter 5: time 18434.07ms
iter 6: time 18438.49ms
iter 7: time 18438.72ms
iter 8: time 18440.96ms
iter 9: time 18445.63ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 40
Overriding: n_embd = 5120
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 572.14M
iter 0: time 2823.70ms
iter 1: time 9337.50ms
iter 2: time 9382.35ms
iter 3: time 9416.83ms
iter 4: time 9422.83ms
iter 5: time 9429.09ms
iter 6: time 9431.99ms
iter 7: time 9435.91ms
iter 8: time 9437.02ms
iter 9: time 9437.25ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 56
Overriding: n_embd = 7168
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 977.16M
iter 0: time 18005.77ms
iter 1: time 69926.57ms
iter 2: time 70278.45ms
iter 3: time 70325.98ms
iter 4: time 70363.32ms
iter 5: time 70317.50ms
iter 6: time 70301.27ms
iter 7: time 70305.85ms
iter 8: time 70297.11ms
iter 9: time 70350.68ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 56
Overriding: n_embd = 7168
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 977.16M
iter 0: time 9358.96ms
iter 1: time 35405.19ms
iter 2: time 35737.97ms
iter 3: time 35838.82ms
iter 4: time 35855.73ms
iter 5: time 35880.91ms
iter 6: time 35863.10ms
iter 7: time 35865.67ms
iter 8: time 35867.92ms
iter 9: time 35875.52ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 56
Overriding: n_embd = 7168
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 977.16M
iter 0: time 4798.18ms
iter 1: time 17900.41ms
iter 2: time 18056.29ms
iter 3: time 18101.56ms
iter 4: time 18107.55ms
iter 5: time 18114.99ms
iter 6: time 18118.05ms
iter 7: time 18180.67ms
iter 8: time 18211.58ms
iter 9: time 18216.63ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 72
Overriding: n_embd = 9216
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 1482.85M
iter 0: time 7397.36ms
iter 1: time 29577.38ms
iter 2: time 29809.91ms
iter 3: time 29925.90ms
iter 4: time 29951.75ms
iter 5: time 29964.90ms
iter 6: time 29974.79ms
iter 7: time 29981.55ms
iter 8: time 29993.03ms
iter 9: time 29984.64ms
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 1
Overriding: n_head = 96
Overriding: n_embd = 12288
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 2430.11M
iter 0: time 6465.03ms
iter 1: time 14902.93ms
iter 2: time 14980.19ms
iter 3: time 15069.14ms
iter 4: time 15088.53ms
iter 5: time 15112.15ms
iter 6: time 15121.42ms
iter 7: time 15125.04ms
iter 8: time 15128.40ms
iter 9: time 15135.74ms
