/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 64
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 47419.75ms
iter 1: time 2993.68ms
iter 2: time 3001.03ms
iter 3: time 3008.67ms
iter 4: time 3008.59ms
iter 5: time 3011.38ms
iter 6: time 3012.19ms
iter 7: time 3015.86ms
iter 8: time 3015.92ms
iter 9: time 3017.46ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 22117.35ms
iter 1: time 1434.53ms
iter 2: time 1436.39ms
iter 3: time 1435.24ms
iter 4: time 1436.63ms
iter 5: time 1435.43ms
iter 6: time 1438.61ms
iter 7: time 1435.61ms
iter 8: time 1439.48ms
iter 9: time 1437.13ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 20664.37ms
iter 1: time 279.27ms
iter 2: time 696.44ms
iter 3: time 695.31ms
iter 4: time 693.92ms
iter 5: time 697.52ms
iter 6: time 694.50ms
iter 7: time 694.07ms
iter 8: time 697.03ms
iter 9: time 693.91ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 19744.36ms
iter 1: time 319.60ms
iter 2: time 303.96ms
iter 3: time 354.64ms
iter 4: time 350.09ms
iter 5: time 350.10ms
iter 6: time 351.65ms
iter 7: time 350.24ms
iter 8: time 350.22ms
iter 9: time 352.04ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 12
Overriding: n_embd = 768
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 45.71M
iter 0: time 19288.22ms
iter 1: time 113.61ms
iter 2: time 180.89ms
iter 3: time 181.44ms
iter 4: time 181.41ms
iter 5: time 184.91ms
iter 6: time 183.54ms
iter 7: time 182.54ms
iter 8: time 181.48ms
iter 9: time 181.43ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 64
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 25317.77ms
iter 1: time 4547.37ms
iter 2: time 5004.06ms
iter 3: time 5007.01ms
iter 4: time 5002.79ms
iter 5: time 5003.18ms
iter 6: time 5011.84ms
iter 7: time 5010.70ms
iter 8: time 5011.41ms
iter 9: time 5016.10ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 22963.83ms
iter 1: time 2414.64ms
iter 2: time 2333.63ms
iter 3: time 2371.32ms
iter 4: time 2373.56ms
iter 5: time 2375.81ms
iter 6: time 2377.03ms
iter 7: time 2372.77ms
iter 8: time 2376.47ms
iter 9: time 2376.22ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 20735.04ms
iter 1: time 1169.68ms
iter 2: time 1169.15ms
iter 3: time 1169.77ms
iter 4: time 1170.05ms
iter 5: time 1170.94ms
iter 6: time 1171.00ms
iter 7: time 1171.41ms
iter 8: time 1170.99ms
iter 9: time 1171.33ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 28871.57ms
iter 1: time 486.38ms
iter 2: time 582.56ms
iter 3: time 578.49ms
iter 4: time 579.33ms
iter 5: time 580.75ms
iter 6: time 578.34ms
iter 7: time 581.36ms
iter 8: time 578.64ms
iter 9: time 581.72ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 16
Overriding: n_embd = 1024
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 64.10M
iter 0: time 19788.04ms
iter 1: time 131.79ms
iter 2: time 301.97ms
iter 3: time 306.27ms
iter 4: time 303.64ms
iter 5: time 302.65ms
iter 6: time 304.01ms
iter 7: time 305.66ms
iter 8: time 302.86ms
iter 9: time 303.25ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 64
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 63060.00ms
iter 1: time 16363.43ms
iter 2: time 16446.11ms
iter 3: time 16481.21ms
iter 4: time 16506.45ms
iter 5: time 16519.11ms
iter 6: time 16569.39ms
iter 7: time 16576.42ms
iter 8: time 16583.84ms
iter 9: time 16587.13ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 33977.28ms
iter 1: time 7713.46ms
iter 2: time 7966.54ms
iter 3: time 7971.38ms
iter 4: time 7974.25ms
iter 5: time 7976.99ms
iter 6: time 7982.72ms
iter 7: time 8004.03ms
iter 8: time 8006.84ms
iter 9: time 8013.00ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 22836.63ms
iter 1: time 3894.70ms
iter 2: time 3894.61ms
iter 3: time 3896.89ms
iter 4: time 3897.48ms
iter 5: time 3900.49ms
iter 6: time 3899.96ms
iter 7: time 3902.14ms
iter 8: time 3901.75ms
iter 9: time 3900.84ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 21264.83ms
iter 1: time 1777.06ms
iter 2: time 1941.29ms
iter 3: time 1942.39ms
iter 4: time 1941.71ms
iter 5: time 1942.46ms
iter 6: time 1943.59ms
iter 7: time 1943.79ms
iter 8: time 1944.38ms
iter 9: time 1943.92ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 32
Overriding: n_embd = 2048
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 153.36M
iter 0: time 20388.02ms
iter 1: time 659.07ms
iter 2: time 1003.09ms
iter 3: time 1002.69ms
iter 4: time 1002.79ms
iter 5: time 1002.65ms
iter 6: time 1002.88ms
iter 7: time 1003.78ms
iter 8: time 1003.35ms
iter 9: time 1003.43ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 64
Overriding: n_head = 64
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 38173.05ms
iter 1: time 24688.54ms
iter 2: time 24717.55ms
iter 3: time 24734.49ms
iter 4: time 24749.99ms
iter 5: time 24759.51ms
iter 6: time 24781.76ms
iter 7: time 24785.23ms
iter 8: time 24778.31ms
iter 9: time 24792.65ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 32
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 29866.50ms
iter 1: time 10320.80ms
iter 2: time 12080.35ms
iter 3: time 12086.25ms
iter 4: time 12096.63ms
iter 5: time 12101.44ms
iter 6: time 12102.02ms
iter 7: time 12101.10ms
iter 8: time 12100.19ms
iter 9: time 12107.58ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 32
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 24282.10ms
iter 1: time 5941.67ms
iter 2: time 5946.62ms
iter 3: time 5949.48ms
iter 4: time 5950.99ms
iter 5: time 5957.10ms
iter 6: time 5957.28ms
iter 7: time 5954.80ms
iter 8: time 5961.83ms
iter 9: time 5962.66ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 32
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 22352.25ms
iter 1: time 2641.00ms
iter 2: time 2971.28ms
iter 3: time 2972.49ms
iter 4: time 2975.98ms
iter 5: time 2977.52ms
iter 6: time 2977.59ms
iter 7: time 2977.55ms
iter 8: time 2978.36ms
iter 9: time 2976.92ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 32
Overriding: n_embd = 2560
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 207.43M
iter 0: time 20598.39ms
iter 1: time 1518.27ms
iter 2: time 1517.53ms
iter 3: time 1519.57ms
iter 4: time 1518.67ms
iter 5: time 1520.05ms
iter 6: time 1519.54ms
iter 7: time 1520.43ms
iter 8: time 1521.03ms
iter 9: time 1521.15ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 32
Overriding: n_embd = 4096
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 407.38M
iter 0: time 39986.10ms
iter 1: time 25462.54ms
iter 2: time 29201.33ms
iter 3: time 29252.37ms
iter 4: time 29263.15ms
iter 5: time 29268.70ms
iter 6: time 29265.02ms
iter 7: time 29277.74ms
iter 8: time 29278.30ms
iter 9: time 29255.40ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 32
Overriding: n_embd = 4096
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 407.38M
iter 0: time 28925.68ms
iter 1: time 13925.62ms
iter 2: time 14516.54ms
iter 3: time 14528.67ms
iter 4: time 14540.93ms
iter 5: time 14546.44ms
iter 6: time 14547.15ms
iter 7: time 14549.27ms
iter 8: time 14553.34ms
iter 9: time 14553.61ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 32
Overriding: n_embd = 4096
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 407.38M
iter 0: time 28476.54ms
iter 1: time 3312.33ms
iter 2: time 7335.69ms
iter 3: time 7341.55ms
iter 4: time 7340.80ms
iter 5: time 7343.31ms
iter 6: time 7348.81ms
iter 7: time 7350.52ms
iter 8: time 7355.45ms
iter 9: time 7351.96ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 32
Overriding: n_embd = 4096
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 407.38M
iter 0: time 23216.83ms
iter 1: time 2978.05ms
iter 2: time 3755.90ms
iter 3: time 3756.20ms
iter 4: time 3758.36ms
iter 5: time 3758.72ms
iter 6: time 3760.26ms
iter 7: time 3762.71ms
iter 8: time 3761.76ms
iter 9: time 3769.80ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 32
Overriding: n_head = 40
Overriding: n_embd = 5120
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 572.14M
iter 0: time 45477.08ms
iter 1: time 45103.99ms
iter 2: time 45122.10ms
iter 3: time 45168.91ms
iter 4: time 45166.49ms
iter 5: time 45154.82ms
iter 6: time 45164.48ms
iter 7: time 45139.06ms
iter 8: time 45140.21ms
iter 9: time 45139.41ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 40
Overriding: n_embd = 5120
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 572.14M
iter 0: time 31988.92ms
iter 1: time 22377.64ms
iter 2: time 22417.85ms
iter 3: time 22438.34ms
iter 4: time 22449.18ms
iter 5: time 22456.44ms
iter 6: time 22458.14ms
iter 7: time 22450.49ms
iter 8: time 22457.68ms
iter 9: time 22447.49ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 40
Overriding: n_embd = 5120
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 572.14M
iter 0: time 30849.75ms
iter 1: time 6810.76ms
iter 2: time 11319.17ms
iter 3: time 11318.05ms
iter 4: time 11331.69ms
iter 5: time 11341.19ms
iter 6: time 11344.53ms
iter 7: time 11345.85ms
iter 8: time 11340.83ms
iter 9: time 11346.43ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 40
Overriding: n_embd = 5120
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 572.14M
iter 0: time 25365.11ms
iter 1: time 3963.12ms
iter 2: time 5833.59ms
iter 3: time 5837.51ms
iter 4: time 5839.56ms
iter 5: time 5842.59ms
iter 6: time 5843.19ms
iter 7: time 5850.91ms
iter 8: time 5849.19ms
iter 9: time 5849.84ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 16
Overriding: n_head = 56
Overriding: n_embd = 7168
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 977.16M
iter 0: time 50924.44ms
iter 1: time 32375.23ms
iter 2: time 43214.40ms
iter 3: time 43260.49ms
iter 4: time 43267.96ms
iter 5: time 43251.99ms
iter 6: time 43245.55ms
iter 7: time 43245.91ms
iter 8: time 43240.06ms
iter 9: time 43233.51ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 8
Overriding: n_head = 56
Overriding: n_embd = 7168
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 977.16M
iter 0: time 30749.78ms
iter 1: time 21803.83ms
iter 2: time 21859.05ms
iter 3: time 21879.16ms
iter 4: time 21913.82ms
iter 5: time 21939.36ms
iter 6: time 21950.08ms
iter 7: time 21949.23ms
iter 8: time 21948.46ms
iter 9: time 21947.14ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 56
Overriding: n_embd = 7168
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 977.16M
iter 0: time 32766.91ms
iter 1: time 4561.43ms
iter 2: time 11238.99ms
iter 3: time 11256.80ms
iter 4: time 11270.77ms
iter 5: time 11274.67ms
iter 6: time 11282.62ms
iter 7: time 11285.04ms
iter 8: time 11283.01ms
iter 9: time 11289.36ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 4
Overriding: n_head = 72
Overriding: n_embd = 9216
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 1482.85M
iter 0: time 31062.64ms
iter 1: time 16800.76ms
iter 2: time 18415.53ms
iter 3: time 18452.92ms
iter 4: time 18469.87ms
iter 5: time 18484.84ms
iter 6: time 18486.46ms
iter 7: time 18486.28ms
iter 8: time 18489.43ms
iter 9: time 18502.05ms
/root/accelerate/sparse-ffn/sparse/semi_structured.py:99: UserWarning: The PyTorch API of SparseSemiStructuredTensor is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.sparse module for further information about the project.
  warnings.warn(
Overriding config with config/train_gpt2.py:
Overriding: compile = False
Overriding: wandb_log = False
Overriding: dataset = shakespeare_char
Overriding: batch_size = 1
Overriding: n_head = 96
Overriding: n_embd = 12288
Overriding: n_layer = 1
Overriding: block_size = 2048
number of parameters: 2430.11M
iter 0: time 28613.14ms
iter 1: time 9460.63ms
iter 2: time 9811.62ms
iter 3: time 9826.32ms
iter 4: time 9837.04ms
iter 5: time 9843.98ms
iter 6: time 9846.52ms
iter 7: time 9851.03ms
iter 8: time 9866.68ms
iter 9: time 9885.97ms
